{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Train or execute model to generate texture from picture')\n",
    "parser.add_argument('--input-path', type=str,\n",
    "                    default=\"./data/input/wood\",\n",
    "                    help='Path where input and target images are stored')\n",
    "parser.add_argument('--output-path', type=str,\n",
    "                    default=\"./data/output\",\n",
    "                    help='Path where generated images will be stored')\n",
    "parser.add_argument('--checkpoints-path', type=str,\n",
    "                    default=\"./data/checkpoints\",\n",
    "                    help='Path where generated checkpoints will be stored')\n",
    "parser.add_argument('--hide-plots', action=\"store_true\",\n",
    "                    default=False,\n",
    "                    help='Do not display plots of every ')\n",
    "parser.add_argument('-f')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Configuration\n",
    "INPUT_PATH = args.input_path\n",
    "OUTPUT_PATH = args.output_path\n",
    "CHECKPOINTS_PATH = args.checkpoints_path\n",
    "DISPLAY_PLOTS = not args.hide_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar Functions\n",
    "\n",
    "def normalize(image):\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def load_image(id):\n",
    "    input_img = tf.cast(tf.image.decode_png(tf.io.read_file(INPUT_PATH + \"/\" + id + \"-edges.png\"), channels=3), tf.float32)\n",
    "    target_img = tf.cast(tf.image.decode_png(tf.io.read_file(INPUT_PATH + \"/\" + id + \"-image.png\"), channels=3), tf.float32)\n",
    "    \n",
    "    input_img = normalize(input_img)\n",
    "    target_img = normalize(target_img)\n",
    "\n",
    "    return input_img, target_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# Main\n",
    "\n",
    "image_paths = glob.glob(INPUT_PATH + \"/*image*\")\n",
    "data_size = len(image_paths)\n",
    "\n",
    "ids = list(map(lambda i: \"%.4d\" % (i,), range(data_size)))\n",
    "\n",
    "train_size = round(data_size * 0.80)\n",
    "\n",
    "ids_rand = np.copy(ids)\n",
    "np.random.shuffle(ids_rand)\n",
    "\n",
    "train_ids = ids_rand[:train_size]\n",
    "test_ids = ids_rand[train_size:]\n",
    "\n",
    "train_tensors = list(map(lambda i: load_image(i), train_ids))\n",
    "test_tensors= list(map(lambda i: load_image(i), test_ids))\n",
    "\n",
    "image_size = load_image(ids_rand[0])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = load_image(ids_rand[0])[1]\n",
    "img = (img + 1) / 2\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_tensors,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=(tf.TensorShape([None, None, 3]), tf.TensorShape([None, None, 3]))\n",
    ")\n",
    "train_dataset = train_dataset.batch(1)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: test_tensors,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=(tf.TensorShape([None, None, 3]), tf.TensorShape([None, None, 3]))\n",
    ")\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "for input_img, target_img in train_dataset.take(1):\n",
    "    print(input_img.shape)\n",
    "    plt.imshow((input_img[0,...] + 1) / 2)\n",
    "    plt.show()\n",
    "    \n",
    "    print(target_img.shape)\n",
    "    plt.imshow((target_img[0,...] + 1) / 2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "def downsampler(filters, apply_batch_normalization=True):\n",
    "    \n",
    "    result = Sequential()\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(0, 0.02)\n",
    "    \n",
    "    result.add(Conv2D(\n",
    "        filters,\n",
    "        kernel_size = 4,\n",
    "        strides = 2,\n",
    "        padding = \"same\",\n",
    "        kernel_initializer = initializer,\n",
    "        use_bias = not apply_batch_normalization\n",
    "    ))\n",
    "    \n",
    "    if apply_batch_normalization:\n",
    "        result.add(BatchNormalization())\n",
    "    \n",
    "    result.add(LeakyReLU(alpha = 0.2))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "downsampler(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampler(filters, apply_dropout=False):\n",
    "    result = Sequential()\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(0, 0.02)\n",
    "    \n",
    "    result.add(Conv2DTranspose(\n",
    "        filters,\n",
    "        kernel_size = 4,\n",
    "        strides = 2,\n",
    "        padding = \"same\",\n",
    "        kernel_initializer = initializer,\n",
    "        use_bias = False\n",
    "    ))\n",
    "    \n",
    "    result.add(BatchNormalization())\n",
    "    \n",
    "    if apply_dropout:\n",
    "        result.add(Dropout(0.5))\n",
    "    \n",
    "    result.add(ReLU())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "upsampler(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Generator(input_dim1, input_dim2):\n",
    "    inputs = tf.keras.layers.Input(shape=[input_dim1, input_dim2, 3])\n",
    "    \n",
    "    last_layer = Conv2DTranspose(\n",
    "        filters = 3,\n",
    "        kernel_size = 4,\n",
    "        strides = 2,\n",
    "        padding = \"same\",\n",
    "        kernel_initializer = tf.random_normal_initializer(0, 0.02),\n",
    "        activation = \"tanh\"\n",
    "    )\n",
    "\n",
    "    # Encoder\n",
    "    l_e1 = downsampler(64, apply_batch_normalization = False)(inputs)\n",
    "    l_e2 = downsampler(128)(l_e1)\n",
    "    l_e3 = downsampler(256)(l_e2)\n",
    "    l_e4 = downsampler(512)(l_e3)\n",
    "    l_e5 = downsampler(512)(l_e4)\n",
    "    l_e6 = downsampler(512)(l_e5)\n",
    "    l_e7 = downsampler(512)(l_e6)\n",
    "    l_e8 = downsampler(512)(l_e7)\n",
    "\n",
    "    # Decoder\n",
    "    l_d1 = upsampler(512, apply_dropout = True)(l_e8)\n",
    "    l_d2 = upsampler(512, apply_dropout = True)(concatenate([l_d1, l_e7]))\n",
    "    l_d3 = upsampler(512, apply_dropout = True)(concatenate([l_d2, l_e6]))\n",
    "    l_d4 = upsampler(512)(concatenate([l_d3, l_e5]))\n",
    "    l_d5 = upsampler(256)(concatenate([l_d4, l_e4]))\n",
    "    l_d6 = upsampler(128)(concatenate([l_d5, l_e3]))\n",
    "    l_d7 = upsampler(64)(concatenate([l_d6, l_e2]))\n",
    "    \n",
    "    last = last_layer(l_d7)\n",
    "    \n",
    "    return Model(inputs=[inputs], outputs=last)\n",
    "\n",
    "generator = Generator(image_size[0], image_size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "for input_img, target_img in train_dataset.take(1):\n",
    "    gen_output = generator([((input_img + 1) * 255)], training=False)\n",
    "    plt.imshow(gen_output[0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(input_dim1, input_dim2):\n",
    "    input_img = Input(shape=[input_dim1, input_dim2, 3])\n",
    "    generated_img = Input(shape=[input_dim1, input_dim2, 3])\n",
    "                \n",
    "    l_d1 = downsampler(64, apply_batch_normalization=False)(concatenate([input_img, generated_img]))\n",
    "    l_d2 = downsampler(128)(l_d1)\n",
    "    l_d3 = downsampler(256)(l_d2)\n",
    "    l_d4 = downsampler(512)(l_d3)\n",
    "        \n",
    "    last = Conv2D(\n",
    "        filters = 1,\n",
    "        kernel_size = 4,\n",
    "        strides = 2,\n",
    "        padding = \"same\",\n",
    "        kernel_initializer = tf.random_normal_initializer(0, 0.02),\n",
    "    )(l_d4)\n",
    "    \n",
    "    return Model(inputs=[input_img, generated_img], outputs=last)\n",
    "\n",
    "discriminator = Discriminator(image_size[0], image_size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "for input_img, target_img in train_dataset.take(1):\n",
    "    gen_output = generator([((input_img + 1) * 255)], training=False)\n",
    "    disc_out = discriminator([((input_img + 1) * 255), gen_output], training=False)\n",
    "    \n",
    "    plt.imshow(disc_out[0,...,-1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    \n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    \n",
    "    total_loss = real_loss + generated_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 100\n",
    "\n",
    "def generator_loss(disc_generated_output, generated_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    \n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - generated_output))\n",
    "    \n",
    "    total_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix = CHECKPOINTS_PATH + \"/chkp\"\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    generator_optimizer=generator_optimizer,\n",
    "    discriminator_optimizer=discriminator_optimizer,\n",
    "    generator=generator,\n",
    "    discriminator=discriminator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, test_target, save_filename=False, display_imgs=True):\n",
    "    prediction = model([test_input], training = False)\n",
    "    \n",
    "    if save_filename:\n",
    "        tf.keras.preprocessing.image.save_img(OUTPUT_PATH + '/' + save_filename + \".jpg\", prediction[0, ...])\n",
    "        \n",
    "    if display_imgs:\n",
    "        plt.figure(figsize=(10,10))\n",
    "\n",
    "        display_list = [test_input[0], test_target[0], prediction[0]]\n",
    "        title = [\"Input image\", \"Ground truth\", \"Predicted Image\"]\n",
    "    \n",
    "        for i in range(3):\n",
    "            plt.subplot(1, 3, i+1)\n",
    "            plt.title(title[i])\n",
    "            \n",
    "            plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "            plt.axis(\"off\")\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(input_image, target_image):\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        generated_image = generator([input_image], training=True)\n",
    "    \n",
    "        generated_image_disc = discriminator([generated_image, input_image], training = True)\n",
    "    \n",
    "        target_image_disc = discriminator([target_image, input_image], training = True)\n",
    "    \n",
    "        disc_loss = discriminator_loss(target_image_disc, generated_image_disc)\n",
    "    \n",
    "        gen_loss = generator_loss(generated_image_disc, generated_image, target_image)\n",
    "    \n",
    "        discriminator_grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "        generator_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        \n",
    "        discriminator_optimizer.apply_gradients(zip(discriminator_grads, discriminator.trainable_variables))\n",
    "        generator_optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    \n",
    "    if os.listdir(CHECKPOINTS_PATH):\n",
    "        checkpoint.restore(tf.train.latest_checkpoint(CHECKPOINTS_PATH)).assert_consumed()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        img_counter = 0\n",
    "        for input_image, target_image in train_dataset:\n",
    "            print(\"epoch %d - train: %d / %d\" % (epoch, img_counter, len(train_ids)))\n",
    "            img_counter += 1\n",
    "            train_step(input_image, target_image)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "\n",
    "        img_counter = 0\n",
    "        for input_image, target_image in test_dataset.take(5):\n",
    "            generate_images(generator, input_image, target_image, \"%d_%d\" % (img_counter, epoch), display_imgs=DISPLAY_PLOTS)\n",
    "            img_counter += 1\n",
    "            \n",
    "        if (epoch + 1) % 25 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataset, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
