{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "\n",
    "PATH = \"./data\"\n",
    "\n",
    "INPUT_PATH = PATH + \"/input/wood\"\n",
    "CHECKPOINTS_PATH = PATH + \"/checkpoints\"\n",
    "\n",
    "TYPES = [\"cedar\", \"oak\", \"pine\", \"redwood\"]\n",
    "\n",
    "# Functions\n",
    "\n",
    "def load_dictionary(filename):\n",
    "    fd = open(filename, \"r\")\n",
    "    dictionary = json.loads(fd.read())\n",
    "    fd.close()\n",
    "    return dictionary\n",
    "\n",
    "def generate_label_vector(metafile):\n",
    "    mydict = load_dictionary(metafile)\n",
    "    img_type = mydict[\"type\"]\n",
    "    label_vector = []\n",
    "    for t in TYPES:\n",
    "        if t == img_type:\n",
    "            label_vector.append(1.)\n",
    "        else:\n",
    "            label_vector.append(0.)\n",
    "    return np.array(label_vector).astype(float)\n",
    "\n",
    "def normalize(image):\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def load_image(id):\n",
    "    input_img = tf.cast(tf.image.decode_png(tf.io.read_file(INPUT_PATH + \"/\" + id + \"-edges.png\"), channels=3), tf.float32)\n",
    "    target_img = tf.cast(tf.image.decode_png(tf.io.read_file(INPUT_PATH + \"/\" + id + \"-image.png\"), channels=3), tf.float32)\n",
    "    class_vector = generate_label_vector(INPUT_PATH + \"/\" + id + \"-meta.txt\")\n",
    "    \n",
    "    input_img = normalize(input_img)\n",
    "    target_img = normalize(target_img)\n",
    "\n",
    "    return input_img, target_img, class_vector\n",
    "\n",
    "# Main\n",
    "\n",
    "image_paths = glob.glob(INPUT_PATH + \"/*image*\")\n",
    "data_size = len(image_paths)\n",
    "\n",
    "ids = list(map(lambda i: \"%.4d\" % (i,), range(data_size)))\n",
    "\n",
    "train_size = round(data_size * 0.80)\n",
    "\n",
    "ids_rand = np.copy(ids)\n",
    "np.random.shuffle(ids_rand)\n",
    "\n",
    "train_ids = ids_rand[:train_size]\n",
    "test_ids = ids_rand[train_size:]\n",
    "\n",
    "train_tensors = list(map(lambda i: load_image(i), train_ids))\n",
    "test_tensors= list(map(lambda i: load_image(i), test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = load_image(ids_rand[0])[0].shape\n",
    "\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = load_image(ids_rand[0])[1]\n",
    "img = (img + 1) / 2\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_tensors,\n",
    "    output_types=(tf.float32, tf.float32, tf.float32),\n",
    "    output_shapes=(tf.TensorShape([None, None, 3]), tf.TensorShape([None, None, 3]), tf.TensorShape([None]))\n",
    ")\n",
    "train_dataset = train_dataset.batch(1)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: test_tensors,\n",
    "    output_types=(tf.float32, tf.float32, tf.float32),\n",
    "    output_shapes=(tf.TensorShape([None, None, 3]), tf.TensorShape([None, None, 3]), tf.TensorShape([None]))\n",
    ")\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_img, target_img, class_vector in train_dataset.take(1):\n",
    "    print(input_img.shape)\n",
    "    plt.imshow((input_img[0,...] + 1) / 2)\n",
    "    plt.show()\n",
    "    \n",
    "    print(target_img.shape)\n",
    "    plt.imshow((target_img[0,...] + 1) / 2)\n",
    "    plt.show()\n",
    "    \n",
    "    print(class_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "def downsampler(filters, apply_batch_normalization=True):\n",
    "    \n",
    "    result = Sequential()\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(0, 0.02)\n",
    "    \n",
    "    result.add(Conv2D(\n",
    "        filters,\n",
    "        kernel_size = 4,\n",
    "        strides = 2,\n",
    "        padding = \"same\",\n",
    "        kernel_initializer = initializer,\n",
    "        use_bias = not apply_batch_normalization\n",
    "    ))\n",
    "    \n",
    "    if apply_batch_normalization:\n",
    "        result.add(BatchNormalization())\n",
    "    \n",
    "    result.add(LeakyReLU(alpha = 0.2))\n",
    "    \n",
    "    return result\n",
    "\n",
    "downsampler(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampler(filters, apply_dropout=False):\n",
    "    result = Sequential()\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(0, 0.02)\n",
    "    \n",
    "    result.add(Conv2DTranspose(\n",
    "        filters,\n",
    "        kernel_size = 4,\n",
    "        strides = 2,\n",
    "        padding = \"same\",\n",
    "        kernel_initializer = initializer,\n",
    "        use_bias = False\n",
    "    ))\n",
    "    \n",
    "    result.add(BatchNormalization())\n",
    "    \n",
    "    if apply_dropout:\n",
    "        result.add(Dropout(0.5))\n",
    "    \n",
    "    result.add(ReLU())\n",
    "    \n",
    "    return result\n",
    "\n",
    "upsampler(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_conditioner(input_filters, latent_vector_size):\n",
    "    result = Sequential()\n",
    "        \n",
    "    result.add(Flatten())\n",
    "        \n",
    "    result.add(Dense(input_filters))\n",
    "    result.add(BatchNormalization())\n",
    "    result.add(LeakyReLU(alpha = 0.2))\n",
    "    \n",
    "    result.add(Dense(latent_vector_size))\n",
    "\n",
    "    return result\n",
    "\n",
    "def conditioner(output_dim1, output_dim2, output_dim3):\n",
    "    result = Sequential()\n",
    "        \n",
    "    result.add(Dense(2048))\n",
    "    result.add(LeakyReLU(alpha = 0.2))\n",
    "    result.add(Dropout(0.2))\n",
    "    \n",
    "    result.add(Dense(output_dim1 * output_dim2 * output_dim3))\n",
    "    result.add(BatchNormalization())\n",
    "    result.add(LeakyReLU(alpha = 0.2))\n",
    "    result.add(Dropout(0.2))\n",
    "    \n",
    "    result.add(Reshape((output_dim1, output_dim2, output_dim3)))\n",
    "\n",
    "    return result\n",
    "\n",
    "i = tf.keras.layers.Input(shape=[1, 1, 4])\n",
    "ia = tf.keras.layers.Input(shape=[2])\n",
    "\n",
    "o = pre_conditioner(512, 100)(i)\n",
    "o = conditioner(1, 1, 512)(concatenate([o, ia]))\n",
    "m = Model(inputs=[i, ia], outputs=o)\n",
    "\n",
    "d = tf.cast(np.array([[[[0, 0.5, -0.5, 0]]]]), tf.float32)\n",
    "da = tf.cast(np.array([[0, 1]]), tf.float32)\n",
    "m([d, da], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Generator(input_dim1, input_dim2, class_num):\n",
    "    inputs = tf.keras.layers.Input(shape=[input_dim1, input_dim2, 3])\n",
    "    class_vector = tf.keras.layers.Input(shape=[class_num])\n",
    "    \n",
    "    last_layer = Conv2DTranspose(\n",
    "        filters = 3,\n",
    "        kernel_size = 4,\n",
    "        strides = 2,\n",
    "        padding = \"same\",\n",
    "        kernel_initializer = tf.random_normal_initializer(0, 0.02),\n",
    "        activation = \"tanh\"\n",
    "    )\n",
    "\n",
    "    # Encoder\n",
    "    l_e1 = downsampler(64, apply_batch_normalization = False)(inputs)\n",
    "    l_e2 = downsampler(128)(l_e1)\n",
    "    l_e3 = downsampler(256)(l_e2)\n",
    "    l_e4 = downsampler(512)(l_e3)\n",
    "    l_e5 = downsampler(512)(l_e4)\n",
    "    l_e6 = downsampler(512)(l_e5)\n",
    "    l_e7 = downsampler(512)(l_e6)\n",
    "    l_e8 = downsampler(512)(l_e7)\n",
    "    \n",
    "    # Conditioner\n",
    "    l_c1 = pre_conditioner(int((input_dim1 / 256) * (input_dim2 / 256) * 512), 100)(l_e8)\n",
    "    l_c2 = conditioner(int(input_dim1 / 256), int(input_dim1 / 256), 512)(concatenate([l_c1, class_vector]))\n",
    "\n",
    "    # Decoder\n",
    "    l_d1 = upsampler(512, apply_dropout = True)(concatenate([l_c2, l_e8]))\n",
    "    l_d2 = upsampler(512, apply_dropout = True)(concatenate([l_d1, l_e7]))\n",
    "    l_d3 = upsampler(512, apply_dropout = True)(concatenate([l_d2, l_e6]))\n",
    "    l_d4 = upsampler(512)(concatenate([l_d3, l_e5]))\n",
    "    l_d5 = upsampler(256)(concatenate([l_d4, l_e4]))\n",
    "    l_d6 = upsampler(128)(concatenate([l_d5, l_e3]))\n",
    "    l_d7 = upsampler(64)(concatenate([l_d6, l_e2]))\n",
    "    \n",
    "    last = last_layer(l_d7)\n",
    "    \n",
    "    return Model(inputs=[inputs, class_vector], outputs=last)\n",
    "\n",
    "generator = Generator(image_size[0], image_size[1], len(TYPES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_img, target_img, vector_class in train_dataset.take(1):\n",
    "    gen_output = generator([((input_img + 1) * 255), vector_class], training=False)\n",
    "    plt.imshow(gen_output[0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_vector(dim1, dim2):\n",
    "    def f(x):\n",
    "        x = tf.expand_dims(x, axis = 1)\n",
    "        x = tf.expand_dims(x, axis = 1)\n",
    "        x = tf.tile(x, [1, dim1, dim2, 1])\n",
    "        return x\n",
    "    return f\n",
    "\n",
    "def Discriminator(input_dim1, input_dim2, class_num):\n",
    "    input_img = Input(shape=[input_dim1, input_dim2, 3])\n",
    "    generated_img = Input(shape=[input_dim1, input_dim2, 3])\n",
    "    class_vector = Input(shape=[class_num])\n",
    "                \n",
    "    l_d1 = downsampler(64, apply_batch_normalization=False)(concatenate([input_img, generated_img]))\n",
    "    l_l1 = Lambda(expand_vector(int(input_dim1 / 2), int(input_dim2 / 2)))(class_vector)\n",
    "\n",
    "    l_d2 = downsampler(128)(concatenate([l_d1, l_l1]))\n",
    "    l_d3 = downsampler(256)(l_d2)\n",
    "    l_d4 = downsampler(512)(l_d3)\n",
    "        \n",
    "    last = Conv2D(\n",
    "        filters = 1,\n",
    "        kernel_size = 4,\n",
    "        strides = 2,\n",
    "        padding = \"same\",\n",
    "        kernel_initializer = tf.random_normal_initializer(0, 0.02),\n",
    "    )(l_d4)\n",
    "    \n",
    "    return Model(inputs=[input_img, generated_img, class_vector], outputs=last)\n",
    "\n",
    "discriminator = Discriminator(image_size[0], image_size[1], len(TYPES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_img, target_img, class_vector in train_dataset.take(1):\n",
    "    gen_output = generator([((input_img + 1) * 255), class_vector], training=False)\n",
    "    disc_out = discriminator([((input_img + 1) * 255), gen_output, class_vector], training=False)\n",
    "    \n",
    "    plt.imshow(disc_out[0,...,-1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    \n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    \n",
    "    total_loss = real_loss + generated_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 100\n",
    "\n",
    "def generator_loss(disc_generated_output, generated_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    \n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - generated_output))\n",
    "    \n",
    "    total_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix = CHECKPOINTS_PATH + \"/chkp\"\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    generator_optimizer=generator_optimizer,\n",
    "    discriminator_optimizer=discriminator_optimizer,\n",
    "    generator=generator,\n",
    "    discriminator=discriminator\n",
    ")\n",
    "\n",
    "#checkpoint.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH)).assert_consumed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar, class_vector, save_filename=False, display_imgs=True):\n",
    "    prediction = model([test_input, class_vector], training = False)\n",
    "    \n",
    "    if save_filename:\n",
    "        tf.keras.preprocessing.image.save_img(PATH + '/output/' + save_filename + \".jpg\", prediction[0, ...])\n",
    "        \n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    display_list = [test_input[0], tar[0], prediction[0]]\n",
    "    title = [\"Input image\", \"Ground truth\", \"Predicted Image\"]\n",
    "    \n",
    "    if display_imgs:\n",
    "        for i in range(3):\n",
    "            plt.subplot(1, 3, i+1)\n",
    "            plt.title(title[i])\n",
    "            \n",
    "            plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "            plt.axis(\"off\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(input_image, target_image, class_vector):\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        generated_image = generator([input_image, class_vector], training=True)\n",
    "    \n",
    "        generated_image_disc = discriminator([generated_image, input_image, class_vector], training = True)\n",
    "    \n",
    "        target_image_disc = discriminator([target_image, input_image, class_vector], training = True)\n",
    "    \n",
    "        disc_loss = discriminator_loss(target_image_disc, generated_image_disc)\n",
    "    \n",
    "        gen_loss = generator_loss(generated_image_disc, generated_image, target_image)\n",
    "    \n",
    "        discriminator_grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "        generator_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        \n",
    "        discriminator_optimizer.apply_gradients(zip(discriminator_grads, discriminator.trainable_variables))\n",
    "        generator_optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        img_counter = 0\n",
    "        for input_image, target_image, class_vector in train_dataset:\n",
    "            print(\"epoch %d - train: %d / %d\" % (epoch, img_counter, len(train_ids)))\n",
    "            img_counter += 1\n",
    "            train_step(input_image, target_image, class_vector)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "\n",
    "        img_counter = 0\n",
    "        for input_image, target_image, class_vector in test_dataset.take(5):\n",
    "            generate_images(generator, input_image, target_image, class_vector, \"%d_%d\" % (img_counter, epoch), display_imgs=True)\n",
    "            img_counter += 1\n",
    "            \n",
    "        if (epoch + 1) % 25 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataset, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
