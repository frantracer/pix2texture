{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Train or execute model to generate texture from picture')\n",
    "parser.add_argument('--training-input', type=str,\n",
    "                    default=\"./data/training/input/wood\",\n",
    "                    help='Path where PNG input images with suffix \"-edges.png\" and \"-image.png\" for training are stored')\n",
    "parser.add_argument('--training-output', type=str,\n",
    "                    default=\"./data/training/output/wood\",\n",
    "                    help='Path where generated testing images will be stored during training')\n",
    "parser.add_argument('--evaluation-input', type=str,\n",
    "                    default=\"./data/evaluation/input/wood\",\n",
    "                    help='Path where PNG input images with suffix \"-edges.png\" and \"-image.png\" for evaluation are stored')\n",
    "parser.add_argument('--evaluation-output', type=str,\n",
    "                    default=\"./data/evaluation/output/wood\",\n",
    "                    help='Path where generated images will be stored')\n",
    "parser.add_argument('--checkpoints-path', type=str,\n",
    "                    default=\"./checkpoints\",\n",
    "                    help='Path where generated checkpoints will be stored')\n",
    "parser.add_argument('--epochs', type=int,\n",
    "                    default=100,\n",
    "                    help='Number of epochs to run the training')\n",
    "parser.add_argument('--hide-plots', action=\"store_true\",\n",
    "                    default=False,\n",
    "                    help='Do not display plots of every image')\n",
    "parser.add_argument('--skip-training', action=\"store_true\",\n",
    "                    default=False,\n",
    "                    help='Skip training step')\n",
    "parser.add_argument('--skip-evaluation', action=\"store_true\",\n",
    "                    default=False,\n",
    "                    help='Skip evaluation step')\n",
    "parser.add_argument('-f')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration global variables\n",
    "\n",
    "TRAINING_INPUT_PATH = args.training_input\n",
    "TRAINING_OUTPUT_PATH = args.training_output\n",
    "EVALUATION_INPUT_PATH = args.evaluation_input\n",
    "EVALUATION_OUTPUT_PATH = args.evaluation_output\n",
    "CHECKPOINTS_PATH = args.checkpoints_path\n",
    "DISPLAY_PLOTS = not args.hide_plots\n",
    "EPOCHS = args.epochs\n",
    "RUN_TRAINING = not args.skip_training\n",
    "RUN_EVALUATION = not args.skip_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES = [\"cedar\", \"oak\", \"pine\", \"redwood\"]\n",
    "\n",
    "TRAINING_INPUT_PATH = \"./data/training/input/wood_by_class\"\n",
    "TRAINING_OUTPUT_PATH = \"./data/training/output/wood_by_class\"\n",
    "EVALUATION_INPUT_PATH = \"./data/evaluation/input/wood_by_class\"\n",
    "EVALUATION_OUTPUT_PATH = \"./data/evaluation/output/wood_by_class\"\n",
    "\n",
    "CHECKPOINTS_PATH = \"./checkpoints_cgan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create directories if needed\n",
    "if RUN_TRAINING:\n",
    "\n",
    "    if not os.path.exists(TRAINING_OUTPUT_PATH):\n",
    "        os.makedirs(TRAINING_OUTPUT_PATH)\n",
    "\n",
    "    if not os.path.exists(CHECKPOINTS_PATH):\n",
    "        os.makedirs(CHECKPOINTS_PATH)\n",
    "        \n",
    "if RUN_EVALUATION:\n",
    "    \n",
    "    if not os.path.exists(EVALUATION_OUTPUT_PATH):\n",
    "        os.makedirs(EVALUATION_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Auxiliar Functions\n",
    "\n",
    "def load_dictionary(filename):\n",
    "    fd = open(filename, \"r\")\n",
    "    dictionary = json.loads(fd.read())\n",
    "    fd.close()\n",
    "    return dictionary\n",
    "\n",
    "def generate_label_vector(metafile):\n",
    "    mydict = load_dictionary(metafile)\n",
    "    img_type = mydict[\"type\"]\n",
    "    label_vector = []\n",
    "    for t in TYPES:\n",
    "        if t == img_type:\n",
    "            label_vector.append(1.)\n",
    "        else:\n",
    "            label_vector.append(0.)\n",
    "    return np.array(label_vector).astype(float)\n",
    "\n",
    "def normalize(image):\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def load_image_set(input_dir, id_str):\n",
    "    input_img = tf.cast(tf.image.decode_png(tf.io.read_file(input_dir + \"/\" + id_str + \"-edges.png\"), channels=3), tf.float32)\n",
    "    input_img = normalize(input_img)\n",
    "    \n",
    "    target_img = tf.cast(tf.image.decode_png(tf.io.read_file(input_dir + \"/\" + id_str + \"-image.png\"), channels=3), tf.float32)\n",
    "    target_img = normalize(target_img)\n",
    "\n",
    "    class_vector = generate_label_vector(input_dir + \"/\" + id_str + \"-meta.txt\")\n",
    "\n",
    "    return input_img, target_img, class_vector\n",
    "\n",
    "def load_image_path(input_dir, id_str):\n",
    "    input_img = tf.cast(tf.image.decode_png(tf.io.read_file(input_dir + \"/\" + id_str + \"-edges.png\"), channels=3), tf.float32)\n",
    "    input_img = normalize(input_img)\n",
    "    \n",
    "    class_vector = generate_label_vector(input_dir + \"/\" + id_str + \"-meta.txt\")\n",
    "\n",
    "    return input_img, class_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Main\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    image_paths = glob.glob(TRAINING_INPUT_PATH + \"/*-edges.png\")\n",
    "    image_filenames = list(map(lambda s: s.split(\"/\")[-1], image_paths))\n",
    "    data_size = len(image_paths)\n",
    "\n",
    "    p = re.compile('(.+)-edges\\.png')\n",
    "    ids = sorted(list(map(lambda s: p.search(s).group(1), image_filenames)))\n",
    "\n",
    "    image_size = load_image_set(TRAINING_INPUT_PATH, ids[0])[0].shape\n",
    "    \n",
    "    train_size = round(data_size * 0.80)\n",
    "\n",
    "    np.random.shuffle(ids)\n",
    "\n",
    "    train_ids = ids[:train_size]\n",
    "    test_ids = ids[train_size:]\n",
    "\n",
    "    train_tensors = list(map(lambda i: load_image_set(TRAINING_INPUT_PATH, i), train_ids))\n",
    "    test_tensors = list(map(lambda i: load_image_set(TRAINING_INPUT_PATH, i), test_ids))\n",
    "    \n",
    "if RUN_EVALUATION:\n",
    "    image_paths = sorted(glob.glob(EVALUATION_INPUT_PATH + \"/*-edges.png\"))\n",
    "    image_filenames = list(map(lambda s: s.split(\"/\")[-1], image_paths))\n",
    "    \n",
    "    p = re.compile('(.+)-edges\\.png')\n",
    "    ids = sorted(list(map(lambda s: p.search(s).group(1), image_filenames)))\n",
    "    \n",
    "    image_size = load_image_path(EVALUATION_INPUT_PATH, ids[0])[0].shape\n",
    "\n",
    "    eval_ids = ids\n",
    "\n",
    "    eval_tensors = list(map(lambda filename: load_image_path(EVALUATION_INPUT_PATH, filename), eval_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    print(ids[0])\n",
    "    img = load_image_set(TRAINING_INPUT_PATH, train_ids[0])[1]\n",
    "    plt.imshow(img * 0.5 + 0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TRAINING:\n",
    "    train_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: train_tensors,\n",
    "        output_types=(tf.float32, tf.float32, tf.float32),\n",
    "        output_shapes=(tf.TensorShape([None, None, 3]), tf.TensorShape([None, None, 3]), tf.TensorShape([None]))\n",
    "    )\n",
    "    train_dataset = train_dataset.batch(1)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: test_tensors,\n",
    "        output_types=(tf.float32, tf.float32, tf.float32),\n",
    "        output_shapes=(tf.TensorShape([None, None, 3]), tf.TensorShape([None, None, 3]), tf.TensorShape([None]))\n",
    "    )\n",
    "    test_dataset = test_dataset.batch(1)\n",
    "\n",
    "if RUN_EVALUATION:\n",
    "    eval_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: eval_tensors,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=(tf.TensorShape([None, None, 3]), tf.TensorShape([None]))\n",
    "    )\n",
    "    eval_dataset = eval_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "if RUN_TRAINING:    \n",
    "    for (input_img, target_img, class_vector), id_str in zip(train_dataset.take(1), train_ids):\n",
    "        print(id_str)\n",
    "        print(\"Class -> \" + str(class_vector))\n",
    "        print(input_img.shape)\n",
    "        plt.imshow((input_img[0,...] * 0.5 + 0.5))\n",
    "        plt.show()\n",
    "\n",
    "        print(target_img.shape)\n",
    "        plt.imshow((target_img[0,...] * 0.5 + 0.5))\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "def downsampler(filters, apply_batch_normalization=True):\n",
    "    \n",
    "    result = Sequential()\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(0, 0.02)\n",
    "    \n",
    "    result.add(Conv2D(\n",
    "        filters,\n",
    "        kernel_size = 4,\n",
    "        strides = 2,\n",
    "        padding = \"same\",\n",
    "        kernel_initializer = initializer,\n",
    "        use_bias = not apply_batch_normalization\n",
    "    ))\n",
    "    \n",
    "    if apply_batch_normalization:\n",
    "        result.add(BatchNormalization())\n",
    "    \n",
    "    result.add(LeakyReLU(alpha = 0.2))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "downsampler(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampler(filters, apply_dropout=False):\n",
    "    result = Sequential()\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(0, 0.02)\n",
    "    \n",
    "    result.add(Conv2DTranspose(\n",
    "        filters,\n",
    "        kernel_size = 4,\n",
    "        strides = 2,\n",
    "        padding = \"same\",\n",
    "        kernel_initializer = initializer,\n",
    "        use_bias = False\n",
    "    ))\n",
    "    \n",
    "    result.add(BatchNormalization())\n",
    "    \n",
    "    if apply_dropout:\n",
    "        result.add(Dropout(0.5))\n",
    "    \n",
    "    result.add(ReLU())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "upsampler(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_conditioner(input_filters, latent_vector_size):\n",
    "    result = Sequential()\n",
    "        \n",
    "    result.add(Flatten())\n",
    "        \n",
    "    result.add(Dense(input_filters))\n",
    "    result.add(BatchNormalization())\n",
    "    result.add(LeakyReLU(alpha = 0.2))\n",
    "    \n",
    "    result.add(Dense(latent_vector_size))\n",
    "\n",
    "    return result\n",
    "\n",
    "def conditioner(output_dim1, output_dim2, output_dim3):\n",
    "    result = Sequential()\n",
    "        \n",
    "    result.add(Dense(2048))\n",
    "    result.add(LeakyReLU(alpha = 0.2))\n",
    "    result.add(Dropout(0.2))\n",
    "    \n",
    "    result.add(Dense(output_dim1 * output_dim2 * output_dim3))\n",
    "    result.add(BatchNormalization())\n",
    "    result.add(LeakyReLU(alpha = 0.2))\n",
    "    result.add(Dropout(0.2))\n",
    "    \n",
    "    result.add(Reshape((output_dim1, output_dim2, output_dim3)))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "info_cell"
    ]
   },
   "outputs": [],
   "source": [
    "i = tf.keras.layers.Input(shape=[1, 1, 4])\n",
    "ia = tf.keras.layers.Input(shape=[2])\n",
    "\n",
    "o = pre_conditioner(512, 100)(i)\n",
    "o = conditioner(1, 1, 512)(concatenate([o, ia]))\n",
    "m = Model(inputs=[i, ia], outputs=o)\n",
    "\n",
    "d = tf.cast(np.array([[[[0, 0.5, -0.5, 0]]]]), tf.float32)\n",
    "da = tf.cast(np.array([[0, 1]]), tf.float32)\n",
    "m([d, da], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Generator(input_dim1, input_dim2, class_num):\n",
    "    inputs = tf.keras.layers.Input(shape=[input_dim1, input_dim2, 3])\n",
    "    class_vector = tf.keras.layers.Input(shape=[class_num])\n",
    "    \n",
    "    last_layer = Conv2DTranspose(\n",
    "        filters = 3,\n",
    "        kernel_size = 4,\n",
    "        strides = 2,\n",
    "        padding = \"same\",\n",
    "        kernel_initializer = tf.random_normal_initializer(0, 0.02),\n",
    "        activation = \"tanh\"\n",
    "    )\n",
    "\n",
    "    # Encoder\n",
    "    l_e1 = downsampler(64, apply_batch_normalization = False)(inputs)\n",
    "    l_e2 = downsampler(128)(l_e1)\n",
    "    l_e3 = downsampler(256)(l_e2)\n",
    "    l_e4 = downsampler(512)(l_e3)\n",
    "    l_e5 = downsampler(512)(l_e4)\n",
    "    l_e6 = downsampler(512)(l_e5)\n",
    "    l_e7 = downsampler(512)(l_e6)\n",
    "    l_e8 = downsampler(512)(l_e7)\n",
    "    \n",
    "    # Conditioner\n",
    "    l_c1 = pre_conditioner(int((input_dim1 / 256) * (input_dim2 / 256) * 512), 100)(l_e8)\n",
    "    l_c2 = conditioner(int(input_dim1 / 256), int(input_dim1 / 256), 512)(concatenate([l_c1, class_vector]))\n",
    "\n",
    "    # Decoder\n",
    "    l_d1 = upsampler(512, apply_dropout = True)(concatenate([l_c2, l_e8]))\n",
    "    l_d2 = upsampler(512, apply_dropout = True)(concatenate([l_d1, l_e7]))\n",
    "    l_d3 = upsampler(512, apply_dropout = True)(concatenate([l_d2, l_e6]))\n",
    "    l_d4 = upsampler(512)(concatenate([l_d3, l_e5]))\n",
    "    l_d5 = upsampler(256)(concatenate([l_d4, l_e4]))\n",
    "    l_d6 = upsampler(128)(concatenate([l_d5, l_e3]))\n",
    "    l_d7 = upsampler(64)(concatenate([l_d6, l_e2]))\n",
    "    \n",
    "    last = last_layer(l_d7)\n",
    "    \n",
    "    return Model(inputs=[inputs, class_vector], outputs=last)\n",
    "\n",
    "generator = Generator(image_size[0], image_size[1], len(TYPES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TRAINING:\n",
    "    for (input_img, target_img, vector_class), id_str in zip(train_dataset.take(1), train_ids):\n",
    "        print(id_str)\n",
    "        gen_output = generator([input_img, vector_class], training = True)\n",
    "        plt.imshow(gen_output[0,...] * 0.5 + 0.5)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_vector(dim1, dim2):\n",
    "    def f(x):\n",
    "        x = tf.expand_dims(x, axis = 1)\n",
    "        x = tf.expand_dims(x, axis = 1)\n",
    "        x = tf.tile(x, [1, dim1, dim2, 1])\n",
    "        return x\n",
    "    return f\n",
    "\n",
    "def Discriminator(input_dim1, input_dim2, class_num):\n",
    "    input_img = Input(shape=[input_dim1, input_dim2, 3])\n",
    "    generated_img = Input(shape=[input_dim1, input_dim2, 3])\n",
    "    class_vector = Input(shape=[class_num])\n",
    "                \n",
    "    l_d1 = downsampler(64, apply_batch_normalization=False)(concatenate([input_img, generated_img]))\n",
    "    l_l1 = Lambda(expand_vector(int(input_dim1 / 2), int(input_dim2 / 2)))(class_vector)\n",
    "\n",
    "    l_d2 = downsampler(128)(concatenate([l_d1, l_l1]))\n",
    "    l_d3 = downsampler(256)(l_d2)\n",
    "    l_d4 = downsampler(512)(l_d3)\n",
    "        \n",
    "    last = Conv2D(\n",
    "        filters = 1,\n",
    "        kernel_size = 4,\n",
    "        strides = 2,\n",
    "        padding = \"same\",\n",
    "        kernel_initializer = tf.random_normal_initializer(0, 0.02),\n",
    "    )(l_d4)\n",
    "    \n",
    "    return Model(inputs=[input_img, generated_img, class_vector], outputs=last)\n",
    "\n",
    "discriminator = Discriminator(image_size[0], image_size[1], len(TYPES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TRAINING:\n",
    "    for (input_img, target_img, class_vector), id_str in zip(train_dataset.take(1), train_ids):\n",
    "        print(id_str)\n",
    "        gen_output = generator([input_img, class_vector], training=True)\n",
    "        disc_out = discriminator([input_img, gen_output, class_vector], training=True)\n",
    "\n",
    "        plt.imshow(disc_out[0,...,-1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    \n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    \n",
    "    total_loss = real_loss + generated_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_loss(input_image, generated_image, target_image):\n",
    "    gray_image = tf.cast(tf.image.rgb_to_grayscale((input_image * 0.5 + 0.5) * 255)[0, ..., -1], tf.uint8)\n",
    "    edges_mask = tf.greater_equal(tf.constant(0, dtype=tf.uint8), gray_image)\n",
    "        \n",
    "    acc_error = 0\n",
    "    for channel_i in range(3):\n",
    "        acc_error += tf.reduce_mean(tf.abs(tf.boolean_mask(target_image[0, ..., channel_i], edges_mask) -\n",
    "                                           tf.boolean_mask(generated_image[0, ..., channel_i], edges_mask)))\n",
    "    acc_error /= 3.0\n",
    "    \n",
    "    return acc_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 100\n",
    "GAMMA = 300\n",
    "\n",
    "def generator_loss(disc_generated_output, generated_output, input_image, target_image):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    \n",
    "    l1_loss = tf.reduce_mean(tf.abs(target_image - generated_output))\n",
    "    e_loss = edge_loss(input_image, generated_output, target_image)\n",
    "    \n",
    "    total_loss = gan_loss + (LAMBDA * l1_loss) + (GAMMA * e_loss)\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(\n",
    "    generator_optimizer=generator_optimizer,\n",
    "    discriminator_optimizer=discriminator_optimizer,\n",
    "    generator=generator,\n",
    "    discriminator=discriminator\n",
    ")\n",
    "\n",
    "checkpoint_manager = tf.train.CheckpointManager(\n",
    "    checkpoint, directory=CHECKPOINTS_PATH, max_to_keep=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar, class_vector, save_filename=False, display_imgs=True):\n",
    "    prediction = model([test_input, class_vector], training = False)\n",
    "    \n",
    "    if save_filename:\n",
    "        tf.keras.preprocessing.image.save_img(PATH + '/output/' + save_filename + \".jpg\", prediction[0, ...])\n",
    "        \n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    display_list = [test_input[0], tar[0], prediction[0]]\n",
    "    title = [\"Input image\", \"Ground truth\", \"Predicted Image\"]\n",
    "    \n",
    "    if display_imgs:\n",
    "        for i in range(3):\n",
    "            plt.subplot(1, 3, i+1)\n",
    "            plt.title(title[i])\n",
    "            \n",
    "            plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "            plt.axis(\"off\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, test_target, class_vector, save_filename_path=\"\", display_imgs=True):\n",
    "    prediction = model([test_input, class_vector], training = True)\n",
    "\n",
    "    if not save_filename_path == \"\":\n",
    "        output_img_data = tf.cast((prediction[0, ...] * 0.5 + 0.5) * 255, tf.uint8)\n",
    "        tf.keras.preprocessing.image.save_img(save_filename_path, output_img_data, scale=False)\n",
    "        \n",
    "    if display_imgs:\n",
    "        plt.figure(figsize=(10,10))\n",
    "\n",
    "        for class_type, class_value in zip(TYPES, class_vector[0]):\n",
    "            if class_value == 1:\n",
    "                class_name = class_type\n",
    "        \n",
    "        display_list = [test_input[0], test_target[0], prediction[0]]\n",
    "        title = [\"Input: %s\" % (class_name,), \"Ground truth\", \"Predicted Image\"]\n",
    "    \n",
    "        for i in range(3):\n",
    "            plt.subplot(1, 3, i+1)\n",
    "            plt.title(title[i])\n",
    "            \n",
    "            plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "            plt.axis(\"off\")\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(input_image, target_image, class_vector):\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        generated_image = generator([input_image, class_vector], training = True)\n",
    "    \n",
    "        generated_image_disc = discriminator([generated_image, input_image, class_vector], training = True)\n",
    "    \n",
    "        target_image_disc = discriminator([target_image, input_image, class_vector], training = True)\n",
    "    \n",
    "        disc_loss = discriminator_loss(target_image_disc, generated_image_disc)\n",
    "    \n",
    "        gen_loss = generator_loss(generated_image_disc, generated_image, input_image, target_image)\n",
    "    \n",
    "        discriminator_grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "        generator_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        \n",
    "        discriminator_optimizer.apply_gradients(zip(discriminator_grads, discriminator.trainable_variables))\n",
    "        generator_optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    \n",
    "    if os.listdir(CHECKPOINTS_PATH):\n",
    "        checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        img_counter = 0\n",
    "        for input_image, target_image, class_vector in train_dataset:\n",
    "            print(\"epoch %d - train: %d / %d\" % (epoch, img_counter, len(train_ids)))\n",
    "            img_counter += 1\n",
    "            train_step(input_image, target_image, class_vector)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for (input_image, target_image, class_vector), id_str in zip(test_dataset, test_ids):\n",
    "            output_path = \"%s/%s_%d.jpg\" % (TRAINING_OUTPUT_PATH, id_str, epoch)\n",
    "            generate_images(generator, input_image, target_image, class_vector, save_filename_path=output_path, display_imgs=DISPLAY_PLOTS)\n",
    "            \n",
    "        if (epoch + 1) % 25 == 0 or epoch + 1 == epochs:\n",
    "            checkpoint_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset):\n",
    "    \n",
    "    if os.listdir(CHECKPOINTS_PATH):\n",
    "        checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "    \n",
    "    for (test_input, class_vector), id_str in zip(dataset, ids):\n",
    "        prediction = generator([test_input, class_vector], training = True)\n",
    "        output_img_path = EVALUATION_OUTPUT_PATH + \"/%s-prediction.jpg\" % (id_str,)\n",
    "        output_img_data = tf.cast((prediction[0, ...] * 0.5 + 0.5) * 255, tf.uint8)\n",
    "        tf.keras.preprocessing.image.save_img(output_img_path, output_img_data, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if RUN_TRAINING:\n",
    "    train(train_dataset, EPOCHS)\n",
    "    \n",
    "if RUN_EVALUATION:\n",
    "    evaluate(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
